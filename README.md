# ğŸ§  AI Text Summarization API (FastAPI + HuggingFace)

A lightweight, production-ready **Text Summarization REST API** built using **FastAPI** and **HuggingFace Inference API**.  
This project allows you to summarize text from:

âœ” File path (local system)  
âœ” Direct file upload  
âœ” Multiple file uploads (TXT & PDF)  

It is designed as a simple demonstration of how to integrate LLMs with modern Python backend services.

---

## ğŸ“ Project Structure

AI_Text_Summarization/
â”‚
â”œâ”€â”€ main.py # FastAPI application + endpoints
â”œâ”€â”€ ai_text_summarize_model.py # HuggingFace model call
â”œâ”€â”€ auto_decode.py # Safe text decoding (supports multi-encoding)
â”œâ”€â”€ model/
â”‚ â””â”€â”€ FilePath.py # Pydantic model for file-path request
â”œâ”€â”€ .env # API keys & configuration (you create this)
â””â”€â”€ requirements.txt # Required Python libraries

## ğŸš€ Features

### âœ” Summaries using HuggingFace Model  
Uses `facebook/bart-large-cnn` via Inference API.

### âœ” 3 REST Endpoints  
1ï¸âƒ£ `/AI-Text-Summarize` â€“ Summarize text from a file path  
2ï¸âƒ£ `/upload-and-summarize` â€“ Upload a single file  
3ï¸âƒ£ `/upload-multiple-summarize` â€“ Upload and summarize multiple files (TXT/PDF)

### âœ” File Handling  
- TXT files: auto-detect encoding using `chardet`  
- PDF files: extracted using `PyPDF2`  
- Validation:
  - Max file count  
  - Max file size  
  - Allowed extensions  

### âœ” Clean Code & Modular Architecture  
Everything is separated for readability and maintainability.

---

## âš™ï¸ Setup Instructions

Follow these steps to run the project on your machine.

---

### 1ï¸âƒ£ Clone the Repository

```bash
git clone <your-repo-link>
cd AI_Text_Summarization

2ï¸âƒ£ Create a Virtual Environment
This ensures isolated package installation.

For Windows:
python -m venv venv
venv\Scripts\activate

For Linux/Mac:
python3 -m venv venv
source venv/bin/activate


3ï¸âƒ£ Install Dependencies
pip install -r requirements.txt

You should see packages like FastAPI, PyPDF2, Python-dotenv, and HuggingFace Hub being installed.

4ï¸âƒ£ Create a HuggingFace API Token


1.Login to HuggingFace
2.Go to Settings â†’ Access Tokens
3.Create a New Token
4.Permissions â†’ Enable Inference
5.Copy the token



5ï¸âƒ£ Create a .env File
Inside the project folder:
HUGGINGFACEHUB_API_TOKEN = "<your-token>"

# Multiple file configuration
MAX_FILES = 5
MAX_FILE_SIZE = 2000000
ALLOWED_EXTENSIONS = [".txt", ".pdf"]


6ï¸âƒ£ Run the FastAPI Server
uvicorn main:app --reload

Now open:
ğŸ“Œ API Docs: http://localhost:8000/docs
ğŸ“Œ ReDoc: http://localhost:8000/redoc

ğŸ§ª API Endpoints Overview
ğŸ”¹ 1. Summarize by File Path
POST /AI-Text-Summarize
{
  "file_path": "C:/Users/.../example.txt"
}


ğŸ”¹ 2. Upload & Summarize Single File
POST /upload-and-summarize
Accepts: .txt, .pdf

ğŸ”¹ 3. Upload Multiple Files
POST /upload-multiple-summarize
âœ” Supports TXT (auto-decoded)
âœ” Supports PDF via PyPDF2
âœ” Generates summary for each file

ğŸ§  Tech Used


FastAPI â€“ REST framework


HuggingFace Inference API â€“ Text summarization


PyPDF2 â€“ PDF text extraction


Chardet â€“ Smart encoding detection


Pydantic â€“ Request validation


Python-dotenv â€“ Environment handling



ğŸ“Œ Future Improvements (Optional Roadmap)


Add authentication with API keys


Add frontend (React/Streamlit) for file upload


Add more models (T5, Pegasus, Llama)


Convert into real production workflow using Docker + Azure



ğŸ™Œ Author
Abhishek Kumar
Python Developer | AI-ML Engineer
